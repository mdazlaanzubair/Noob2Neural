{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdazlaanzubair/Noob2Neural/blob/main/The_DI_DE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INTORUDCTION**\n",
        "\n",
        "### **The DI DE**\n",
        "\n",
        " The **DI**gits **DE**tector is a simple project that uses a neural network to classify the handwritten digits. In this project their were **TWO NEURAL NETWORKS** are formed.\n",
        "\n",
        " In the first neural network there is only **2x layered** architecture will be used i.e. **INPUT LAYER** and **OUTPUT LAYER**. While in the second neural network the same architecture will be followed along with an additional **HIDDEN LAYER** in order to test the performance and improvement if the model."
      ],
      "metadata": {
        "id": "odUTdgBQ9Y4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 1 - IMPORT AND INSTALL REQUISITE LIBRARIES**\n",
        "\n",
        "Following are the dependencies or libraries being used to create the said neural network:\n",
        "\n",
        "*   **TensorFlow** - An open-source software library for machine learning and artificial intelligence. It can be used to develop models for various tasks, including natural language processing, image recognition, handwriting recognition, and different computational-based simulations such as partial differential equations.\n",
        "\n",
        "*   **Keras** - A high-level API of the TensorFlow platform. It provides an approachable, highly-productive interface for solving machine learning (ML) problems, with a focus on modern deep learning.\n",
        "\n",
        "*   **Matplotlib** - A comprehensive library for creating static, animated, and interactive visualizations in Python. It create publication quality plots. Make interactive figures that can zoom, pan, update.\n",
        "\n",
        "*   **Numpy** - It is used to perform a wide variety of mathematical operations on arrays. It adds powerful data structures to Python that guarantee efficient calculations with arrays and matrices and it supplies an enormous library of high-level mathematical functions that operate on these arrays and matrices.\n",
        "\n",
        "*   **Tabulate** - It is a module that display data in a tabulated form.\n",
        "\n",
        "*   **Seaborn** - It is a data visualization library based on Matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics."
      ],
      "metadata": {
        "id": "ovxciwRHo5bS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMjoeqMf6ESd"
      },
      "outputs": [],
      "source": [
        "# IMPORTING NECESSARY LIBRARIES\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as ploter\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "import seaborn as sn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 2 - LOAD THE DATASET**\n",
        "\n",
        "Before creating a model a collection of data is required that is used to train and test algorithms and models. For the purpose of **The DiDe** a dataset of **MNIST** will be used.\n",
        "\n",
        "**MNIST Dataset** - Modified National Institute of Standards and Technology is a large collection of handwritten digits, ranging from **0** to **9**. It is a very popular dataset in the field of image processing. It is often used for benchmarking machine learning algorithms.\n",
        "\n",
        "The dataset is being loaded using **KERAS**:\n",
        "\n",
        "*   **x_train** - Hold the features of training data which in this case is a **TWO-DIMENSION** array of an image grid holding **RGB** values of each pixel of the image.\n",
        "\n",
        "*   **y_train** - Holds the label of corresponding image in **x_train** which in this case the **DIGIT** in the image.\n",
        "\n",
        "*   Similarly, for **x_test** and **y_test**, the word **TRAIN** and **TEST** represents which dataset is for training and which one is for testing."
      ],
      "metadata": {
        "id": "iXxZQRllrsMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING MNIST DATASET USING KERAS\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# SINCE THE MODEL IS SHOWING POOR ACCURACY THEREFORE THE DATASET WILL BE\n",
        "# RE-SCALED TO GET OPTIMAL RESULTS - IN THIS CASE THE SCALE WILL RANGE\n",
        "# BETWEEN 0 TO 1 - FOR THAT ALL THE RGB VALUES IN THE DATASET WILL BE\n",
        "# DIVIDED BY 255\n",
        "x_train = X_train / 255\n",
        "x_test = X_test / 255\n",
        "\n",
        "# PREVIEWING OUR LOADED DATA USING MATPLOT LIBRARY\n",
        "print(\"Y Train Label =>\", y_train[0])\n",
        "print(\"X Train Feature =>\", ploter.matshow(x_train[0]))"
      ],
      "metadata": {
        "id": "muTrtciECx_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 3 - FLATTEN THE DATA**\n",
        "\n",
        "As discussed in the **STEP 2**, the dataset contains a **TWO-DIMENSION** array of an image grid holding RGB values of each pixel of the image. Which is difficult and complex for performing operation specially when using large data.\n",
        "\n",
        "Therefore, the concept of flattening takes place where the **TWO-DIMENSION** array will be converted into **ONE-DIMENSION** array by reshaping the dataset object."
      ],
      "metadata": {
        "id": "R_4cF-PPxnNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AFTER PRINTING OUT THE CURRENT SHAPE DATASET OBJECT IT IS REVEALED THAT\n",
        "# THE FIRST VALUE OF OBJECT REPRESENTS THE NUMBER OF DATA, THE SECOND AND THIRD\n",
        "# VALUES REPRESENTS ACTUAL TWO-DIMENSION ARRAY OF A 2D IMAGE\n",
        "\n",
        "# \"x_train\" HAS 60000 IMAGES AND EACH IMAGE IS A SET IF 28 x 28 GRID\n",
        "# TWO-DIMENSIONAL ARRAY, SAME IS FOR \"x_test\"\n",
        "\n",
        "print(\"x_train =>\", x_train.shape)\n",
        "print(\"x_test =>\", x_test.shape)\n",
        "\n",
        "\n",
        "print(\"\\n===================================\\n\")\n",
        "\n",
        "# THE DATA IS NOW RESHAPED FROM TWO-DIMENSIONAL TO ONE-DIMENSIONAL ARRAY\n",
        "# WHICH MAKES IT EASIER TO PERFORM MATHEMATICAL CALCULATION / OPERATIONS\n",
        "\n",
        "# 2D TO 1D CONVERSION IS BEING DONE BY \"numpy\" RE-SHAPE FUNCTION\n",
        "x_train_flattened = x_train.reshape(len(x_train), 28 * 28)\n",
        "x_test_flattened = x_test.reshape(len(x_test), 28 * 28)\n",
        "\n",
        "# AFTER RESHAPING THE \"x_train\" STILL HAS 60000 IMAGES BUT THIS TIME THE IMAGE\n",
        "# IS A ONE-DIMENSIONAL ARRAY, SAME IS FOR \"x_test\"\n",
        "\n",
        "print(\"x_train_flattened =>\", x_train_flattened.shape)\n",
        "print(\"x_test_flattened =>\", x_test_flattened.shape)"
      ],
      "metadata": {
        "id": "87lvMcIvHedi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 4 - CREATE A NEURAL NETWORK**\n",
        "\n",
        "After loading and flattening the data now is the time to create a **SEQUENTIAL NEURAL NETWORK** using **KERAS**.\n",
        "\n",
        "*   **SEQUENTIAL** - It is a model constructor that connects neurons in a sequence network, where neurons are arranged in layers, passing information forward. It accepts two parameters as follows:\n",
        "\n",
        "    *   **name** - It take a name of a model.\n",
        "\n",
        "    *   **layers** - It take a list of layers to be incorporated in the model.\n",
        "\n",
        "*   **layers.Dense** - It represents that the layers of the model are \"densely connected\", where each neuron is connected to all neurons in the previous layer. It accepts four parameters as follows:\n",
        "    \n",
        "    * **units** *(required)* - This is the most crucial parameter, specifying the number of neurons in the Dense layer. The number of neurons determines the layer's capacity to extract features and learn patterns from the data.\n",
        "    \n",
        "    * **activation** *(optional)* - An activation function applied to the outputs of each neuron. Common choices include \"relu\" for non-linearity, \"sigmoid\" for probability-like outputs, and others.\n",
        "    \n",
        "    * **input_shape** *(optional)* - The expected shape of the input data the layer will receive. This is essential for the first layer when you need to specify the input format (e.g., (28, 28, 1) for 28x28 grayscale images).\n",
        "    \n",
        "    * **kernel_initializer and bias_initializer** *(optional)* - Methods to initialize the weights and biases of the layer, influencing how the layer starts learning."
      ],
      "metadata": {
        "id": "CNEbphmr3mTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MAKING INITIAL MODEL THAT CONSIST OF ONLY TWO LAYERS AND THOSE\n",
        "# ARE \"INPUT\", AND \"OUTPUT\" USING KERAS SEQUENTIAL CONSTRUCTOR\n",
        "\n",
        "# \"units\" - MNIST DATASET HAS 10 DIGITS (0 TO 9) THEREFORE UNITS WILL BE \"10\"\n",
        "# ALL THESE NEURONS TRYING TO LEARN THE FEATURES TO DISTINGUISH BETWEEN DIGITS\n",
        "\n",
        "# \"activation\" - IN THIS CASE \"Sigmoid\" IS THE ACTIVATION FUNCTION\n",
        "# IT WILL OUTPUT VALUE BETWEEN 0 AND 1\n",
        "\n",
        "# INITIALIZING THE MODEL\n",
        "mdl = keras.Sequential(name=\"Two_Layered_DiDe\")\n",
        "\n",
        "# ADDING LAYER TO IT\n",
        "mdl.add(keras.layers.Dense(units=10, input_shape=(784,), activation=\"sigmoid\"))\n",
        "\n",
        "# PRITNING OUT THE SUMMARY OF THE CREATED MODEL\n",
        "mdl.summary()"
      ],
      "metadata": {
        "id": "IAWGnEdcWkpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 5 - TRAIN THE MODEL**\n",
        "\n",
        "After creation of **Two_Layered_DiDe**, it is time provide some training data to help model to learn features of the handwritten digits. But before that there is another crucial step called **COMPILE**. It transforms the simple sequence of layers defined in **STEP 4** into a highly efficient series of matrix transformations that makes it possible for the computer to train the model.\n",
        "\n",
        "This **compile()** function takes three parameters as follows:\n",
        "\n",
        "*   **loss** - It measures the difference between the model's predictions and the actual labels, guiding the learning process by minimizing this difference.\n",
        "\n",
        "*   **optimizer** - It iteratively updates the model's weights and biases based on the calculated loss. It determines how the model learns from its mistakes and improves its predictions.\n",
        "\n",
        "*   **metrics** - This specifies the metrics you want to track during training and evaluation. These metrics give insights into the model's performance on aspects beyond just the loss function."
      ],
      "metadata": {
        "id": "nfrqDpnT_FSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WHILE COMPILATION OF THE MODEL FOLLOWING CONFIGURATIONS ARE BEING USED\n",
        "\n",
        "# \"loss\" - \"sparse_categorical_crossentropy\" LOSS FUNCTION IS APPROPRIATE FOR\n",
        "# MULTI-CLASS CLASSIFICATION TASKS WHERE LABELS ARE PROVIDED AS INTEGERS\n",
        "# REPRESENTING THE CLASS CATEGORY (E.G., DIGIT RECOGNITION).\n",
        "\n",
        "# \"optimizer\" - \"adam\" IS A POPULAR AND EFFICIENT OPTIMIZER CHOICE FOR VARIOUS\n",
        "# TASKS. DIFFERENT OPTIMIZERS LIKE \"SGD\" OR \"RMSPROP\" HAVE SPECIFIC STRENGTHS\n",
        "# AND WEAKNESSES DEPENDING ON THE PROBLEM.\n",
        "\n",
        "# \"metrics\" - \"accuracy\" IS A COMMON METRIC FOR CLASSIFICATION TASKS, MEASURING\n",
        "# THE PERCENTAGE OF CORRECT PREDICTIONS. OTHER METRICS LIKE \"precision\",\n",
        "# \"recall\", OR \"F1-score\" COULD BE USED DEPENDING ON THE PROBLEM'S FOCUS.\n",
        "\n",
        "# MODEL IS BEING COMPILED AFTER AFOREMENTIONED CONFIGURATIONS\n",
        "mdl.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# AFTER COMPILATION, THE MODEL IS TRAINED ON A FLATTENED TRAINING DATASET\n",
        "# WHERE:\n",
        "# \"x_train_flattened\" - IS FLATTENED TRAINING DATA (FEATURES)\n",
        "# \"y_train\" - IS CORRESPONDING LABEL OF TRAINING DATA (FEATURES)\n",
        "# \"epochs\" - IS THE NUMBER OF TIME THE MODEL RUNS THROUGH ENTIRE TRAINING DATA\n",
        "# \"batch_size\" - IS THE NUMBER OF SAMPLES TO BE PROCESSED IN EACH STEP\n",
        "\n",
        "mdl.fit(x_train_flattened, y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "lPYF4wnCn57t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 6 - EVALUATE THE ACCURACY**\n",
        "\n",
        "After the training now its time to test the accuracy on a traoining dataset."
      ],
      "metadata": {
        "id": "fxseaVgJIrQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# USING \"evaluate()\" FUNCTION THE ACCURACY OF THE MODEL WILL BE TESTED\n",
        "# ON THE UNSEEN DATA\n",
        "\n",
        "loss, accuracy = mdl.evaluate(x_test_flattened, y_test)\n",
        "\n",
        "print(\"Test loss:\", loss)\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "vNeqsWG8JCuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 7 - TEST PREDICTION**\n",
        "\n",
        "After getting the accuracy the prediction of the model will be tested"
      ],
      "metadata": {
        "id": "n5SzB7JKJ_Hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PRINTING OUT ONE IMAGE FROM TEST DATATSET OF 10000 IMAGES\n",
        "print(\"========================================================================\")\n",
        "print(\"FOLLOWING ARE THE ACTUAL VALUES OF 90 NUMBER IMAGE FROM THE TEST DATASET\")\n",
        "print(\"========================================================================\\n\")\n",
        "print(\"Label for Image Number 90 =>\", y_test[90])\n",
        "print(\"\\n\", ploter.matshow(x_test[90]))"
      ],
      "metadata": {
        "id": "_pCXhCtzKUot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A PREDICTION WILL BE DONE BY JUST PASSING 90 NUMBER IMAGE FROM THE\n",
        "# FLATTENED DATASET TO VERIFY THE RESULTS AS ABOVE\n",
        "predictions = mdl.predict(x_test_flattened)\n",
        "\n",
        "# SINCE THE PREDICTION IS DONE NOW EXTRACTING ONLY SINGLE-ONE FOR VERIFICATION\n",
        "# WHICH IS IMAGE NUMBER 90\n",
        "prediction = predictions[90]\n",
        "\n",
        "# INITIALIZING TABLE WITH COLUMNS\n",
        "table = [[\"S#\", \"DIGIT\", \"CONFIDENCE\"]]\n",
        "\n",
        "# SINCE THE MODEL HAS 10 UNITS IN OUTPUT LAYER THEREFORE EACH PREDICTION\n",
        "# 10 RESULTS WITH THE ACCURACY / CONFIDENCE LEVEL THEREFORE FOLLOWING LOOP\n",
        "# IS BEING RUN THROUGH EACH OF THE 10 RESULTS AND APPENDING IT TABLE ROW\n",
        "for i, confidence in enumerate(prediction):\n",
        "  table.append([i + 1, i, confidence])\n",
        "\n",
        "# PRINTING THE TABLE\n",
        "print(tabulate(table, tablefmt=\"grid\"))\n",
        "\n",
        "# THE MAXIMUM VALUE WILL REPRESENT THE MOST ACCURATE PREDICTION IT WILL BE\n",
        "# EXTRACTED BY NUMPY \"argmax()\" FUNCTION\n",
        "print(\"\\nTHE MODEL SHOW MORE CONFIDENCE ON:\", np.argmax(prediction))"
      ],
      "metadata": {
        "id": "Z0AfJjnzNKD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 8 - PERFORMANCE MATRIX**\n",
        "\n",
        "To calculate the performance of the model a confusion matrix will be made to test and evaluate the **ERRORS** and **ACCURACY** in predicting digits."
      ],
      "metadata": {
        "id": "pKz4pr0Joorb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SINCE WE HAVE 10 CLASS (O TO 9) THEREFORE THE MODEL PREDICTS\n",
        "# THE LIKELIHOOD RANGING FROM O TO 1 USING \"Sigmoid Function\" WHICH\n",
        "# REPRESENTS THE PROBABLITIES FOR EACH CLASS\n",
        "\n",
        "# TO COMPUTE THE CONFUSION MATRIX, DISCRETE CLASS IS REQUIRED THEREFORE\n",
        "# ALL THE PROBABILITIES VECTORS WILL BE CONVERTED INTO DISCRETE CLASS LABELS\n",
        "\n",
        "# \"argmax()\" FUNCTION WILL GET THE MAXIMUM VALUE / HIGH PROBABLITY VECTOR FROM\n",
        "# SPECIFIED AXIS FOR EACH PREDICTION AND THE PREDICTION ARRAY CONVERTED INTO\n",
        "# SINGLE DISCRETE CLASS LABLE ARRAY\n",
        "single_label_array = np.argmax(predictions, axis=1)\n",
        "\n",
        "# USING TENSORFLOW CONFUSION MATRIX FOR THE PURPOSE\n",
        "cm = tf.math.confusion_matrix(labels=y_test, predictions=single_label_array)\n",
        "\n",
        "# IN ORDER TO BEAUTIFY PLOTTING the MATRIX USING SEABORN LIBRARY\n",
        "ploter.figure(figsize=(10, 8))\n",
        "sn.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "ploter.xlabel('Predicted Labels')\n",
        "ploter.ylabel('True Labels')\n",
        "ploter.title('Confusion Matrix')"
      ],
      "metadata": {
        "id": "tTv9i0Nzpw4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REPEATING FROM STEP 4**\n",
        "\n",
        "After **CREATING**, **TESTING**, and **EVALUATING** the **2x layered** architecture of **The Di De** model. Now its time to add a **HIDDEN LAYER** in order to test the performance and improvement if the model."
      ],
      "metadata": {
        "id": "3GjCVIT14KW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# INITIALIZING THE MODEL\n",
        "model = keras.Sequential(name=\"Three_Layered_DiDe\")\n",
        "\n",
        "# ADDING HIDDEN LAYER TO IT\n",
        "model.add(keras.layers.Dense(units=100, input_shape=(784,), activation=\"relu\"))\n",
        "\n",
        "# OUTPUT LAYER\n",
        "model.add(keras.layers.Dense(units=10, activation=\"sigmoid\"))\n",
        "\n",
        "# MODEL IS BEING COMPILED ON SAME CONFIGURATIONS AS IN STEP 5\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# MODEL IS BEING TRAINED AS IN STEP 5\n",
        "model.fit(x_train_flattened, y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "P-xFlH1Q5yMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATING PERFORMANCE ON TEST DATASET AS IN STEP 6\n",
        "loss, accuracy = mdl.evaluate(x_test_flattened, y_test)\n",
        "\n",
        "print(\"Test loss:\", loss)\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "zDFwLgJQ69a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DOING PREDICTIONS AS IN STEP 7\n",
        "predictions = model.predict(x_test_flattened)\n",
        "\n",
        "# COMPUTING CONFUSION MATRIX AS IN STEP 8\n",
        "single_label_array = np.argmax(predictions, axis=1)\n",
        "\n",
        "# USING TENSORFLOW CONFUSION MATRIX FOR THE PURPOSE\n",
        "cm = tf.math.confusion_matrix(labels=y_test, predictions=single_label_array)\n",
        "\n",
        "# PLOTTING MATRIX USING SEABORN LIBRARY\n",
        "ploter.figure(figsize=(10, 8))\n",
        "sn.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "ploter.xlabel('Predicted Labels')\n",
        "ploter.ylabel('True Labels')\n",
        "ploter.title('Confusion Matrix')"
      ],
      "metadata": {
        "id": "ZJUO2DrM7hfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CONCLUSION**\n",
        "\n",
        "An experiment has been conduted where a **NEURAL NETWORK** has been made to detect the handwritten numbers.\n",
        "\n",
        "Initially the model is create by using a simple **2x layered** architecture. And, the data was directly exposed to the model without scaling which caused a lot of errors while predicting. However, then the data is scaled between 0 to 1 in order to minimize the error occurance. After normalization the following results are observed:\n",
        "\n",
        "* **Test Loss** - 26%\n",
        "* **Test Accuracy** - 93%\n",
        "\n",
        "After successful testing and evaluation a **HIDDEN LAYER** is added to the existing model which does not show any furher improvement in the model accuracy but definitly decrease the errors as per the computed **CONFUSION MATRIX**.\n",
        "\n"
      ],
      "metadata": {
        "id": "YDlSuNlq8W5Z"
      }
    }
  ]
}